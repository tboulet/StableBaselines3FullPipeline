# ===== Training & eval numerical parameters =====

# Number of environment timestep to train the agent
timesteps: 10000
# Frequency of evaluating the agent. Each <eval_freq> timesteps, the agent is evaluated for <n_eval_episodes> episodes
eval_freq: 1000
# Number of episodes to evaluate the agent for
n_eval_episodes: 10
# Whether to render episodes at evaluation time
do_render: False
# The seed used for this run
seed: 1234
# The number of parallel environments to use. If >= 2, a VecEnv will be used instead of a single environment
n_envs: 4


# ===== Logging parameters =====

# The level of verbosity of the CLI
verbose: 1
# Whether to log metrics on WandB
do_wandb: False
# Whether to log metrics on Tensorboard
do_tensorboard: True
# The base log path, used in some cases
log_path: "logs"
# The path to the tensorboard logs
log_path_tb: "logs/tensorboard"
# The base path to SB3 models
models_path: "models"
# The path to store the best model of each algorithm on each environment
best_model_path: "models/best_model"
# The path to store the final model (not necessarily the best) of each run
final_model_path: "models/final_model"
# The path to the model or directory of model to load on the agent.
# If its None, a new model will be created.
# If it's a file, it will be loaded as a pretrained model.
# If it's a directory, it's best model according to <checkpoint_criteria> will be loaded.
checkpoint: null
# The criteria used to select the best model in a directory, either "time", "timesteps" or "reward"
checkpoint_criteria : "time"


# ===== Misc parameters =====

# Use of GPU (cpu, cuda,...)
device: "cpu"
# Name of the project
project_name : "RLProject"